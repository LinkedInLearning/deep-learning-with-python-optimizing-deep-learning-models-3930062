{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4762486a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h1>Hyperparameter Tuning a Deep Learning Model in Python</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11963cc7",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of systematically searching for the optimal combination of model parameters prior to training. These parameters, such as the number of hidden layers, the dropout rates between layers, the optimizer learning rate, and training batch size, play a critical role in determining the performance and generalizability of a deep learning model. Effective hyperparameter tuning can significantly improve model accuracy and robustness. In this tutorial, we will use the MNIST digit classification task to illustrate how to leverage Keras Tuner to discover the best configuration of hyperparameters for a deep learning model in Python.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this tutorial, you will:\n",
    "+ Understand the importance of hyperparameter tuning in deep learning.\n",
    "+ Learn how to define and parameterize a tunable model using Keras Tuner.\n",
    "+ Explore the use of Hyperband, an efficient tuning algorithm, to optimize hyperparameters like layer sizes, dropout rates, learning rates, and batch sizes.\n",
    "+ Evaluate the performance of a tuned model on unseen data and compare it to a baseline model.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Before we begin, ensure you have:\n",
    "+ Basic knowledge of Python programming (variables, functions, classes).\n",
    "+ Familiarity with the fundamentals of how to build a deep learning model in Python using Keras.\n",
    "+ A Python (version 3.x) environment with the `tensorflow`, `keras`, and `keras_tuner`packages installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887bb87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>1. Import and Preprocess the Data</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96c17b",
   "metadata": {},
   "source": [
    "We start by importing the data. For this tutorial, we'll use the **MNIST dataset**, a classic dataset in the machine learning community. It consists of 70,000 grayscale images of handwritten digits ranging from 0 to 9. Each image is 28 x 28 pixels, and the dataset is divided into 60,000 training images and 10,000 testing images. Our goal will be to develop a model that learns to correctly identify a handritten digit given the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "keras.utils.set_random_seed(1234)\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffff433d",
   "metadata": {},
   "source": [
    "Our deep learning model expects the images as a vector of size 784 (i.e. 28 $\\times$ 28). So, let's flatten the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(60000, 28 * 28)\n",
    "test_images = test_images.reshape(10000, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb7cc6",
   "metadata": {},
   "source": [
    "The model also expects the image pixel values scaled. Let's do that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d2d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf76519",
   "metadata": {},
   "source": [
    "Finally, we also need to one-hot encode the image labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c41f2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>2. Define the Baseline Model Architecture</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980c61be",
   "metadata": {},
   "source": [
    "The baseline model consists of an input layer with 784 nodes, two hidden layers with 32 and 16 nodes (respectively), and an output layer with 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "model = keras.Sequential([\n",
    "    Input(shape = (784,)),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(16, activation = 'relu'),\n",
    "    Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a222d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>3. Train and Evaluate the Baseline Model</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906d178",
   "metadata": {},
   "source": [
    "Next, we compile and train the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a769eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images, \n",
    "    train_labels,\n",
    "    epochs = 10,\n",
    "    validation_split = 0.1,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6312f3d",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model's performance against the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc702831",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Note:</b> To learn more about deep learning and how to build a deep learning model in Python using Keras, refer to  the LinkedIn Learning course titled <b>\"Deep Learning with Python: Foundations\"</b>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e7da3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\"><h2>4. Define the Tunable Model Architecture</h2></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de094de4",
   "metadata": {},
   "source": [
    "Before we search for the optimal hyperparameters for our model, we need to define a function that specifies the architectural blueprint of the model. The blueprint will incorporate hyperparameters for the number of units per layer, dropout rates, and the optimizer learning rate. Keras Tuner will invoke this function multiple times with different hyperparameter values in order to find an optimal combination that maximizes validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba5d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
